# Template for Spark Job Server Docker config
# You can easily override the spark master through SPARK_MASTER env variable
#
# Spark Cluster / Job Server configuration
spark {
  #
  master = "local[*]"
  master = ${?SPARK_MASTER}

  # Default # of CPUs for jobs to use for Spark standalone cluster
  job-number-cpus = 4

  jobserver {
    port = 8090
    jobdao = spark.jobserver.io.JobSqlDAO

    context-per-jvm = true

    sqldao {
      # Directory where default H2 driver stores its data. Only needed for H2.
      rootdir = /database

      # Full JDBC URL / init string.  Sorry, needs to match above.
      # Substitutions may be used to launch job-server, but leave it out here in the default or tests won't pass
      jdbc.url = "jdbc:h2:file:/database/h2-db"
    }
  }

  # predefined Spark contexts
  # contexts {
  #   my-low-latency-context {
  #     num-cpu-cores = 1           # Number of cores to allocate.  Required.
  #     memory-per-node = 512m         # Executor memory per node, -Xmx style eg 512m, 1G, etc.
  #   }
  #   # define additional contexts here
  # }

  # universal context configuration.  These settings can be overridden, see README.md
  context-settings {
    num-cpu-cores = 2           # Number of cores to allocate.  Required.
    memory-per-node = 512m         # Executor memory per node, -Xmx style eg 512m, #1G, etc.

    # in case spark distribution should be accessed from HDFS (as opposed to being installed on every mesos slave)
    # spark.executor.uri = "hdfs://namenode:8020/apps/spark/spark.tgz"

    # uris of jars to be loaded into the classpath for this context. Uris is a string list, or a string separated by commas ','
    
    # Datastreams & Beam jars
    dependent-jar-uris = ["file:///opt/datastreams-deps/dataflow-dsl-0.1.0-SNAPSHOT.jar", "file:///opt/datastreams-deps/beam-compiler-0.1.0-SNAPSHOT.jar", "file:///opt/datastreams-deps/beam-runners-spark-0.2.0-incubating-SNAPSHOT-spark-app.jar", "file:///opt/datastreams-deps/scalaz-core_2.11-7.2.0.jar", "file:///opt/datastreams-deps/scalacheck_2.11-1.12.5.jar", "file:///opt/datastreams-deps/lift-json_2.11-2.6.2.jar", "file:///opt/datastreams-deps/graph-json_2.11-1.11.0.jar", "file:///opt/datastreams-deps/graph-core_2.11-1.11.0.jar", "file:///opt/datastreams-deps/graph-constrained_2.11-1.11.0.jar", "file:///opt/datastreams-deps/play-iteratees_2.11-2.5.0.jar", "file:///opt/datastreams-deps/jackson-datatype-jsr310-2.7.1.jar", "file:///opt/datastreams-deps/joda-convert-1.8.1.jar", "file:///opt/datastreams-deps/jackson-datatype-jdk8-2.7.1.jar", "file:///opt/datastreams-deps/scala-stm_2.11-0.7.jar", "file:///opt/datastreams-deps/play-datacommons_2.11-2.5.0.jar", "file:///opt/datastreams-deps/play-functional_2.11-2.5.0.jar", "file:///opt/datastreams-deps/play-json_2.11-2.5.0.jar", "file:///opt/datastreams-deps/play-json-schema-validator_2.11-0.8.0.jar", "file:///opt/datastreams-deps/test-interface-1.0.jar", "file:///opt/datastreams-deps/scalap-2.11.1.jar", "file:///opt/datastreams-deps/scala-compiler-2.11.1.jar", "file:///opt/datastreams-deps/scala-xml_2.11-1.0.2.jar", "file:///opt/datastreams-deps/scala-parser-combinators_2.11-1.0.1.jar"]

    # If you wish to pass any settings directly to the sparkConf as-is, add them here in passthrough,
    # such as hadoop connection settings that don't use the "spark." prefix
    passthrough {
      #es.nodes = "192.1.1.1"
    }
  }

  # This needs to match SPARK_HOME for cluster SparkContexts to be created successfully
  home = "/usr/local/spark"
}

# Note that you can use this file to define settings not only for job server,
# but for your Spark jobs as well.  Spark job configuration merges with this configuration file as defaults.
